{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]\n",
      "[[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]]\n"
     ]
    }
   ],
   "source": [
    "# Test generation/Reshape\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# A = np.array\n",
    "# np.repeat(8,2,2,2)\n",
    "A = np.arange(8)\n",
    "B = A.reshape(4,2)\n",
    "print(A)\n",
    "print(B)\n",
    "# help(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "[1 2 3 4]\n",
      "[1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "C = np.arange(4).reshape(2,2)\n",
    "D = np.arange(1,5).reshape(2,2)\n",
    "# .rehsape(2,2)\n",
    "\n",
    "C = np.arange(4)\n",
    "D = np.arange(1,5)\n",
    "\n",
    "Z = np.array([1,1,2,2])\n",
    "\n",
    "print(C)\n",
    "print(D)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -2 -2]\n",
      "[-1 -1 -1 -1]\n",
      "[1 1 2 2]\n",
      "-6\n"
     ]
    }
   ],
   "source": [
    "print((C-D)*Z)\n",
    "print((C-D))\n",
    "print(Z)\n",
    "print(np.matmul(C-D,Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 4 6]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-91fc2997a6d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)"
     ]
    }
   ],
   "source": [
    "print(C * 2)\n",
    "print(np.matmul(C,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6\n",
      "-4\n"
     ]
    }
   ],
   "source": [
    "print(np.sum((C-D)*Z))\n",
    "print(np.sum(C-D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[ 0  2  6 12]\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "E = np.sum(C * D)\n",
    "E_ = C * D\n",
    "print(E)\n",
    "print(E_)\n",
    "F = np.matmul(C,D)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "Bad:  W_new =  -24.875025 . b_new =  -25.124950000000002\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-db2768836e9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mlr\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMSEStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# print(b)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-984111b4c743>\u001b[0m in \u001b[0;36mMSEStep\u001b[0;34m(X, y, W, b, learn_rate)\u001b[0m\n\u001b[1;32m     58\u001b[0m          )\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mW_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlearn_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)"
     ]
    }
   ],
   "source": [
    "# 1D Test\n",
    "\n",
    "A = np.array([0,1])\n",
    "B = A\n",
    "\n",
    "A = np.array([0,1])\n",
    "B = np.array([1,-101])\n",
    "\n",
    "print(A)\n",
    "\n",
    "W_start = 0.5\n",
    "b_start = 0.0001\n",
    "lr      = 0.5\n",
    "\n",
    "W,b = MSEStep(A, B, W_start, b_start, learn_rate = lr)\n",
    "print(W,b)\n",
    "# print(b)\n",
    "\n",
    "for i in range(10):\n",
    "    W,b =  MSEStep(A, B, W, b, learn_rate = lr)\n",
    "    print(W,b)\n",
    "    text = \"done\"\n",
    "\n",
    "#     y_hat = W * X + b\n",
    "\n",
    "#     W_new --> W + learn_rate * (y - y_hat) * X\n",
    "#     b_new --> b + learn_rate * (y - y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.matmul(Err,X) =  [[21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]\n",
      " [21.89358908]]\n",
      "np.sum(Err * X) =  -203.697585763\n",
      "sum(Err * X) =  [-4.87897689e+00 -6.15193775e+00 -2.56812562e+00 -9.61666481e+00\n",
      " -1.15080140e+01 -5.40766399e+00 -6.61024921e+00 -5.53946411e+00\n",
      " -9.33908432e+00 -9.33908432e+00 -4.52542234e+00 -5.59506877e+00\n",
      " -5.01533167e+00 -9.54151312e+00 -9.24381626e+00 -8.83101966e+00\n",
      "  4.93420200e-03 -4.52542234e+00 -5.84342361e+00 -5.55714500e+00\n",
      "  4.93420200e-03 -6.31539901e+00 -1.97004341e+00 -5.40766399e+00\n",
      " -9.78376346e+00 -5.93198621e+00 -5.88258093e+00 -9.24381626e+00\n",
      " -8.89978219e+00 -7.37059076e+00 -7.47724543e+00 -5.78715473e+00]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-4edd914fc65d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mregression_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminiBatchGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;31m# plot the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-4edd914fc65d>\u001b[0m in \u001b[0;36mminiBatchGD\u001b[0;34m(X, y, batch_size, learn_rate, num_iter)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMSEStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mregression_coef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mregression_coef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Setting a random seed, feel free to change it and see different solutions.\n",
    "np.random.seed(42)\n",
    "# np.random.seed(100)\n",
    "\n",
    "\n",
    "# TODO: Fill in code in the function below to implement a gradient descent\n",
    "# step for linear regression, following a squared error rule. See the docstring\n",
    "# for parameters and returned variables.\n",
    "def MSEStep(X, y, W, b, learn_rate = 0.005):\n",
    "    \"\"\"\n",
    "    This function implements the gradient descent step for squared error as a\n",
    "    performance metric.\n",
    "    \n",
    "    Parameters\n",
    "    X : array of predictor features\n",
    "    y : array of outcome values\n",
    "    W : predictor feature coefficients\n",
    "    b : regression function intercept\n",
    "    learn_rate : learning rate\n",
    "\n",
    "    Returns\n",
    "    W_new : predictor feature coefficients following gradient descent step\n",
    "    b_new : intercept following gradient descent step\n",
    "    \"\"\"\n",
    "\n",
    "#---STEP 0: Examine NP ndarray theory\n",
    "\n",
    "\n",
    "    \n",
    "#---STEP 1: Examine Theory    \n",
    "    \n",
    "#     Error = 1/2 * (y - y_hat)^2\n",
    "#     del/(del w1) (Error) = -(y - y_hat)x\n",
    "#     del/(del w2) (Error) = -(y - y_hat)\n",
    "    \n",
    "#     wi --> wi - alpha * (del Error)/(del w1)\n",
    "#     w1 --> w1 - alpha * (-(y - y_hat)x)\n",
    "#     w2 --> w2 - alpha * (-(y - y_hat))\n",
    "\n",
    "#---STEP 2: Outline scalar solution \n",
    "\n",
    "#     y_hat = W * X + b\n",
    "\n",
    "#     W_new --> W + learn_rate * (y - y_hat) * X\n",
    "#     b_new --> b + learn_rate * (y - y_hat)\n",
    "\n",
    "#---STEP 3: Array solution \n",
    "#     np.sum((y - y_hat) * X)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    y_hat = X * W + b\n",
    "    Err = y - y_hat\n",
    "    \n",
    "#     print(\"np.sum((y - y_hat))\",np.sum((y - y_hat)))\n",
    "#     print(\"sum(y - y_hat)\"     ,sum(y - y_hat))\n",
    "#     print(\"Err.sum()\"     ,Err.sum())\n",
    "    \n",
    "    \n",
    "    \n",
    "    W_new = W + learn_rate * np.sum((y - y_hat) * X)\n",
    "    b_new = b + learn_rate * np.sum((y - y_hat)    )\n",
    "    \n",
    "#     print(\"Bad:  W_new = \",W_new,\". b_new = \",b_new\n",
    "#           , \". y_hat = \",y_hat\n",
    "#          )\n",
    "    \n",
    "    y_hat = np.matmul(X,W) + b\n",
    "\n",
    "    W_new = W + learn_rate * np.matmul(y - y_hat,X)\n",
    "    b_new = b + learn_rate * sum(y - y_hat)\n",
    "    \n",
    "#     print(\"Good: W_new = \",W_new,\". b_new = \",b_new\n",
    "#           , \". y_hat = \",y_hat\n",
    "#          )   \n",
    "\n",
    "    \n",
    "    y_hat = np.matmul(X,W) + b\n",
    "    Err = y - y_hat\n",
    "\n",
    "    print(\"np.matmul(Err,X) = \",np.matmul(Err,X))\n",
    "    print(\"np.sum(Err * X) = \",np.sum(Err * X))\n",
    "    print(\"sum(Err * X) = \",sum(Err * X))\n",
    "    \n",
    "    W_new = W + learn_rate * np.matmul(Err,X)\n",
    "    b_new = b + learn_rate * sum((Err)   )\n",
    "    \n",
    "#     print(\"Med: W_new = \",W_new,\". b_new = \",b_new\n",
    "#           , \". y_hat = \",y_hat\n",
    "#          )   \n",
    "\n",
    "    \n",
    "    \n",
    "    # Fill in code\n",
    "    \n",
    "    return W_new, b_new\n",
    "\n",
    "\n",
    "# The parts of the script below will be run when you press the \"Test Run\"\n",
    "# button. The gradient descent step will be performed multiple times on\n",
    "# the provided dataset, and the returned list of regression coefficients\n",
    "# will be plotted.\n",
    "def miniBatchGD(X, y, batch_size = 32, learn_rate = 0.01, num_iter = 100):\n",
    "    \"\"\"\n",
    "    This function performs mini-batch gradient descent on a given dataset.\n",
    "\n",
    "    Parameters\n",
    "    X : array of predictor features\n",
    "    y : array of outcome values\n",
    "    batch_size : how many data points will be sampled for each iteration\n",
    "    learn_rate : learning rate\n",
    "    num_iter : number of batches used\n",
    "\n",
    "    Returns\n",
    "    regression_coef : array of slopes and intercepts generated by gradient\n",
    "      descent procedure\n",
    "    \"\"\"\n",
    "    n_points = X.shape[0]\n",
    "    W = np.zeros(X.shape[1]) # coefficients\n",
    "    b = 0 # intercept\n",
    "    \n",
    "    # run iterations\n",
    "    regression_coef = [np.hstack((W,b))]\n",
    "    for _ in range(num_iter):\n",
    "        batch = np.random.choice(range(n_points), batch_size)\n",
    "        X_batch = X[batch,:]\n",
    "        y_batch = y[batch]\n",
    "        W, b = MSEStep(X_batch, y_batch, W, b, learn_rate)\n",
    "        regression_coef.append(np.hstack((W,b)))\n",
    "    \n",
    "    return regression_coef\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # perform gradient descent\n",
    "    data = np.loadtxt('data.csv', delimiter = ',')\n",
    "    X = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    regression_coef = miniBatchGD(X, y)\n",
    "    \n",
    "    # plot the results\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure()\n",
    "    X_min = X.min()\n",
    "    X_max = X.max()\n",
    "    counter = len(regression_coef)\n",
    "    for W, b in regression_coef:\n",
    "        counter -= 1\n",
    "        color = [1 - 0.92 ** counter for _ in range(3)]\n",
    "        plt.plot([X_min, X_max],[X_min * W + b, X_max * W + b], color = color)\n",
    "    plt.scatter(X, y, zorder = 3)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
